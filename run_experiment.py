#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹å–„ç‰ˆæ¨è–¦ã‚·ã‚¹ãƒ†ãƒ å®Ÿé¨“å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
main_improved.ipynbã®å†…å®¹ã‚’å®Ÿè¡Œ
"""

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¨­å®šï¼ˆGUIãªã—ç’°å¢ƒç”¨ï¼‰
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from janome.tokenizer import Tokenizer
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'DejaVu Sans'

print("="*80)
print("æ”¹å–„ç‰ˆ: ãŠå°å ´ã‚°ãƒ«ãƒ¡æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ  - 3ãƒ‘ã‚¿ãƒ¼ãƒ³æ¯”è¼ƒå®Ÿé¨“")
print("="*80)

# å½¢æ…‹ç´ è§£æã®åˆæœŸåŒ–
print("\n[1/12] å½¢æ…‹ç´ è§£æã®åˆæœŸåŒ–...")
tokenizer = Tokenizer()
print("âœ… å®Œäº†")

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
print("\n[2/12] ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
CSV_FILE_PATH = '/home/user/B2-store-recommend/suku/odaiba_reviews_4.csv'
df = pd.read_csv(CSV_FILE_PATH)
print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,}è¡Œ")
print(f"   ã‚«ãƒ©ãƒ : {df.columns.tolist()}")

# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
print("\n[3/12] ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°...")
df['star_rating'] = pd.to_numeric(df['star_rating'], errors='coerce')
df.dropna(subset=['star_rating', 'category', 'review_text'], inplace=True)
df['category_list'] = df['category'].apply(lambda x: [c.strip() for c in x.split(',') if c.strip()])
print(f"âœ… ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°å¾Œ: {len(df):,}è¡Œ")

# åº—èˆ—ã”ã¨ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’é›†ç´„
print("\n[4/12] åº—èˆ—ã”ã¨ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’é›†ç´„...")
shop_grouped = df.groupby('shop_name').agg({
    'shop_url': 'first',
    'category': 'first',
    'category_list': 'first',
    'star_rating': 'mean',
    'review_text': lambda x: ' '.join(x.dropna().astype(str))
}).reset_index()
print(f"âœ… é›†ç´„å®Œäº†: {len(shop_grouped):,}åº—èˆ—")

# ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰å®šç¾©
print("\n[5/12] ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰å®šç¾©...")
STOP_WORDS = set([
    'ã“ã¨', 'ã‚‚ã®', 'ã‚ˆã†', 'ãŸã‚', 'ã®', 'ã—', 'ã‚“', 'ã•ã‚“', 'ã“ã‚Œ', 'ãã‚Œ', 'ã‚ã‚Œ',
    'ã“ã®', 'ãã®', 'ã‚ã®', 'ã“ã“', 'ãã“', 'ã‚ãã“', 'ä»Š', 'æ™‚', 'æ„Ÿã˜', 'çš„',
    'å ´åˆ', 'æ™‚é–“', 'å ´æ‰€', 'ãŠåº—', 'åº—', 'åº—èˆ—', 'åˆ©ç”¨', 'è¨ªå•', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼'
])

def preprocess_review_improved(text):
    """æ”¹å–„ç‰ˆãƒ¬ãƒ“ãƒ¥ãƒ¼å‰å‡¦ç†: ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰é™¤å» + åè©ãƒ»å½¢å®¹è©æŠ½å‡º"""
    if pd.isna(text):
        return ""

    tokens = []
    for token in tokenizer.tokenize(text):
        pos = token.part_of_speech.split(',')[0]
        word = token.surface

        if pos in ['åè©', 'å½¢å®¹è©'] and word not in STOP_WORDS and len(word) > 1:
            tokens.append(word)

    return " ".join(tokens)

print("âœ… ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰å®šç¾©å®Œäº†")

# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
print("\n[6/12] ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°...")
mlb = MultiLabelBinarizer()
scaler = MinMaxScaler()
tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))

category_features = mlb.fit_transform(shop_grouped['category_list'])
print(f"   ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡: {category_features.shape}")

rating_features = scaler.fit_transform(shop_grouped[['star_rating']])
print(f"   æ˜Ÿè©•ä¾¡ç‰¹å¾´é‡: {rating_features.shape}")

shop_grouped['processed_review'] = shop_grouped['review_text'].apply(preprocess_review_improved)
review_features = tfidf.fit_transform(shop_grouped['processed_review']).toarray()
print(f"   ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰¹å¾´é‡: {review_features.shape}")
print("âœ… ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†")

# ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ç‰¹å¾´é‡è¡Œåˆ—ä½œæˆ
print("\n[7/12] ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ç‰¹å¾´é‡è¡Œåˆ—ä½œæˆ...")
features_p1 = np.concatenate([category_features, rating_features], axis=1)
features_p2 = np.concatenate([category_features, review_features], axis=1)
features_p3 = np.concatenate([category_features, review_features, rating_features], axis=1)
print(f"   P1 (ã‚«ãƒ†ã‚´ãƒª+æ˜Ÿ): {features_p1.shape}")
print(f"   P2 (ã‚«ãƒ†ã‚´ãƒª+ãƒ¬ãƒ“ãƒ¥ãƒ¼): {features_p2.shape}")
print(f"   P3 (ã‚«ãƒ†ã‚´ãƒª+ãƒ¬ãƒ“ãƒ¥ãƒ¼+æ˜Ÿ): {features_p3.shape}")
print("âœ… 3ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å¾´é‡è¡Œåˆ—ä½œæˆå®Œäº†")

# æ¨è–¦é–¢æ•°å®šç¾©
def recommend_with_filter(user_vector, feature_matrix, shop_df,
                          category_filter=None, min_rating=None, top_k=5):
    """ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¯¾å¿œã®æ¨è–¦é–¢æ•°"""
    if user_vector.ndim == 1:
        user_vector = user_vector.reshape(1, -1)

    similarities = cosine_similarity(user_vector, feature_matrix)[0]
    mask = np.ones(len(shop_df), dtype=bool)

    if category_filter:
        category_mask = shop_df['category_list'].apply(
            lambda cats: category_filter in cats
        )
        mask = mask & category_mask

    if min_rating is not None:
        rating_mask = shop_df['star_rating'] >= min_rating
        mask = mask & rating_mask

    filtered_indices = np.where(mask)[0]

    if len(filtered_indices) == 0:
        return pd.DataFrame()

    filtered_similarities = similarities[filtered_indices]
    top_local_indices = np.argsort(filtered_similarities)[-top_k:][::-1]
    top_global_indices = filtered_indices[top_local_indices]

    result = shop_df.iloc[top_global_indices].copy()
    result['é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢'] = similarities[top_global_indices]

    return result[['shop_name', 'star_rating', 'category', 'é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢']]

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ™ã‚¯ãƒˆãƒ«ä½œæˆé–¢æ•°
def create_user_vector_p1(category_query, rating_query):
    """P1: ã‚«ãƒ†ã‚´ãƒª + æ˜Ÿã®æ•°"""
    cat_list = [category_query] if isinstance(category_query, str) else category_query
    cat_vec = mlb.transform([cat_list])
    rating_vec = scaler.transform([[rating_query]])
    return np.concatenate([cat_vec, rating_vec], axis=1).flatten()

def create_user_vector_p2(category_query, review_query):
    """P2: ã‚«ãƒ†ã‚´ãƒª + ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
    cat_list = [category_query] if isinstance(category_query, str) else category_query
    cat_vec = mlb.transform([cat_list])
    processed = preprocess_review_improved(review_query)
    review_vec = tfidf.transform([processed]).toarray()
    return np.concatenate([cat_vec, review_vec], axis=1).flatten()

def create_user_vector_p3(category_query, review_query, rating_query):
    """P3: ã‚«ãƒ†ã‚´ãƒª + ãƒ¬ãƒ“ãƒ¥ãƒ¼ + æ˜Ÿã®æ•°"""
    cat_list = [category_query] if isinstance(category_query, str) else category_query
    cat_vec = mlb.transform([cat_list])
    processed = preprocess_review_improved(review_query)
    review_vec = tfidf.transform([processed]).toarray()
    rating_vec = scaler.transform([[rating_query]])
    return np.concatenate([cat_vec, review_vec, rating_vec], axis=1).flatten()

print("\nâœ… æ¨è–¦é–¢æ•°å®šç¾©å®Œäº†")

# ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªè¨­å®š
print("\n[8/12] ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªè¨­å®š...")
test_scenarios = [
    {
        'name': 'ã‚·ãƒŠãƒªã‚ª1: ã‚¤ã‚¿ãƒªã‚¢ãƒ³ã€ã‚¯ãƒªãƒ¼ãƒŸãƒ¼ãªãƒ‘ã‚¹ã‚¿',
        'category': 'ã‚¤ã‚¿ãƒªã‚¢ãƒ³',
        'review': 'ã‚¯ãƒªãƒ¼ãƒŸãƒ¼ãªãƒ‘ã‚¹ã‚¿ãŒé£Ÿã¹ãŸã„ã€‚ãƒãƒ¼ã‚ºãŸã£ã·ã‚Šã§æ¿ƒåšãªå‘³ã‚ã„',
        'rating': 3.5
    },
    {
        'name': 'ã‚·ãƒŠãƒªã‚ª2: å’Œé£Ÿã€é™ã‹ã§è½ã¡ç€ã„ãŸé›°å›²æ°—',
        'category': 'æ—¥æœ¬æ–™ç†',
        'review': 'é™ã‹ã§è½ã¡ç€ã„ãŸé›°å›²æ°—ã€‚ä¸Šå“ã§ç¹Šç´°ãªå‘³ä»˜ã‘ã€‚ä¸å¯§ãªæ¥å®¢',
        'rating': 4.0
    },
    {
        'name': 'ã‚·ãƒŠãƒªã‚ª3: æµ·é®®ã€æ–°é®®ãªåˆºèº«',
        'category': 'æµ·é®®',
        'review': 'æ–°é®®ãªåˆºèº«ãŒé£Ÿã¹ãŸã„ã€‚é­šã®ç”˜ã¿ãŒæ„Ÿã˜ã‚‰ã‚Œã‚‹ã€‚æµ·ã®å¹¸',
        'rating': 3.8
    }
]
print("âœ… ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªè¨­å®šå®Œäº†")

# å®Ÿé¨“å®Ÿè¡Œ
print("\n[9/12] å®Ÿé¨“å®Ÿè¡Œ: 3ãƒ‘ã‚¿ãƒ¼ãƒ³æ¯”è¼ƒ...")
results = {}

for scenario in test_scenarios:
    print("\n" + "="*80)
    print(f"ğŸ” {scenario['name']}")
    print("="*80)

    cat = scenario['category']
    rev = scenario['review']
    rat = scenario['rating']

    # P1
    print("\nã€P1: ã‚«ãƒ†ã‚´ãƒª + æ˜Ÿã®æ•°ã€‘")
    user_vec_p1 = create_user_vector_p1(cat, rat)
    recs_p1 = recommend_with_filter(
        user_vec_p1, features_p1, shop_grouped,
        category_filter=cat, min_rating=None, top_k=5
    )
    print(recs_p1.to_string(index=False))

    # P2
    print("\nã€P2: ã‚«ãƒ†ã‚´ãƒª + ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‘")
    user_vec_p2 = create_user_vector_p2(cat, rev)
    recs_p2 = recommend_with_filter(
        user_vec_p2, features_p2, shop_grouped,
        category_filter=cat, min_rating=None, top_k=5
    )
    print(recs_p2.to_string(index=False))

    # P3
    print("\nã€P3: ã‚«ãƒ†ã‚´ãƒª + ãƒ¬ãƒ“ãƒ¥ãƒ¼ + æ˜Ÿã®æ•°ã€‘")
    user_vec_p3 = create_user_vector_p3(cat, rev, rat)
    recs_p3 = recommend_with_filter(
        user_vec_p3, features_p3, shop_grouped,
        category_filter=cat, min_rating=None, top_k=5
    )
    print(recs_p3.to_string(index=False))

    results[scenario['name']] = {
        'P1': recs_p1,
        'P2': recs_p2,
        'P3': recs_p3
    }

print("\nâœ… å…¨ã‚·ãƒŠãƒªã‚ªã®å®Ÿé¨“å®Œäº†")

# è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
print("\n[10/12] è©•ä¾¡æŒ‡æ¨™è¨ˆç®—...")
score_stats = []

for scenario_name, patterns in results.items():
    for pattern_name, recs in patterns.items():
        if not recs.empty:
            scores = recs['é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢'].values
            score_stats.append({
                'ã‚·ãƒŠãƒªã‚ª': scenario_name,
                'ãƒ‘ã‚¿ãƒ¼ãƒ³': pattern_name,
                'å¹³å‡é¡ä¼¼åº¦': scores.mean(),
                'æœ€å¤§é¡ä¼¼åº¦': scores.max(),
                'æœ€å°é¡ä¼¼åº¦': scores.min(),
                'å¹³å‡è©•ä¾¡': recs['star_rating'].mean()
            })

stats_df = pd.DataFrame(score_stats)
print("\nğŸ“Š é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢çµ±è¨ˆ")
print(stats_df.to_string(index=False))
print("âœ… è©•ä¾¡æŒ‡æ¨™è¨ˆç®—å®Œäº†")

# è²¢çŒ®åº¦åˆ†æ
print("\n[11/12] ç‰¹å¾´é‡è²¢çŒ®åº¦åˆ†æ...")
contribution = []

for scenario_name in results.keys():
    p1_score = results[scenario_name]['P1']['é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢'].mean() if not results[scenario_name]['P1'].empty else 0
    p2_score = results[scenario_name]['P2']['é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢'].mean() if not results[scenario_name]['P2'].empty else 0
    p3_score = results[scenario_name]['P3']['é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢'].mean() if not results[scenario_name]['P3'].empty else 0

    review_contribution = p2_score - p1_score
    rating_contribution = p3_score - p2_score

    contribution.append({
        'ã‚·ãƒŠãƒªã‚ª': scenario_name,
        'ãƒ¬ãƒ“ãƒ¥ãƒ¼è²¢çŒ®åº¦ (P2-P1)': review_contribution,
        'æ˜Ÿè©•ä¾¡è²¢çŒ®åº¦ (P3-P2)': rating_contribution,
        'P1å¹³å‡é¡ä¼¼åº¦': p1_score,
        'P2å¹³å‡é¡ä¼¼åº¦': p2_score,
        'P3å¹³å‡é¡ä¼¼åº¦': p3_score
    })

contrib_df = pd.DataFrame(contribution)
print("\nğŸ“ˆ ç‰¹å¾´é‡è²¢çŒ®åº¦åˆ†æ")
print(contrib_df.to_string(index=False))
print("âœ… è²¢çŒ®åº¦åˆ†æå®Œäº†")

# å¯è¦–åŒ–
print("\n[12/12] å¯è¦–åŒ–ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ...")

# ã‚°ãƒ©ãƒ•1: ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥é¡ä¼¼åº¦æ¯”è¼ƒ
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for i, scenario in enumerate(test_scenarios):
    scenario_name = scenario['name']

    if scenario_name in results:
        pattern_data = results[scenario_name]

        patterns = ['P1', 'P2', 'P3']
        avg_scores = [
            pattern_data[p]['é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢'].mean() if not pattern_data[p].empty else 0
            for p in patterns
        ]

        axes[i].bar(patterns, avg_scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
        axes[i].set_title(f"{scenario['name'].split(':')[1].strip()}\n(Category: {scenario['category']})",
                         fontsize=10)
        axes[i].set_ylabel('Average Similarity Score', fontsize=9)
        axes[i].set_ylim(0, 1)
        axes[i].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('/home/user/B2-store-recommend/pattern_comparison.png', dpi=150, bbox_inches='tight')
print("âœ… ã‚°ãƒ©ãƒ•ä¿å­˜: pattern_comparison.png")
plt.close()

# ã‚°ãƒ©ãƒ•2: ã‚·ãƒŠãƒªã‚ªåˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³æ¯”è¼ƒ
pivot_data = stats_df.pivot_table(
    index='ãƒ‘ã‚¿ãƒ¼ãƒ³',
    columns='ã‚·ãƒŠãƒªã‚ª',
    values='å¹³å‡é¡ä¼¼åº¦'
)

fig, ax = plt.subplots(figsize=(12, 6))
pivot_data.T.plot(kind='bar', ax=ax, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
ax.set_title('Pattern Comparison Across Scenarios', fontsize=14, fontweight='bold')
ax.set_xlabel('Scenario', fontsize=11)
ax.set_ylabel('Average Similarity Score', fontsize=11)
ax.legend(title='Pattern', fontsize=10)
ax.grid(axis='y', alpha=0.3)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.savefig('/home/user/B2-store-recommend/scenario_comparison.png', dpi=150, bbox_inches='tight')
print("âœ… ã‚°ãƒ©ãƒ•ä¿å­˜: scenario_comparison.png")
plt.close()

# ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
summary_path = '/home/user/B2-store-recommend/experiment_summary.txt'

with open(summary_path, 'w', encoding='utf-8') as f:
    f.write("="*80 + "\n")
    f.write("ãŠå°å ´ã‚°ãƒ«ãƒ¡æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ  - 3ãƒ‘ã‚¿ãƒ¼ãƒ³æ¯”è¼ƒå®Ÿé¨“ çµæœã‚µãƒãƒªãƒ¼\n")
    f.write("="*80 + "\n\n")

    f.write("## ãƒ‡ãƒ¼ã‚¿æ¦‚è¦\n")
    f.write(f"- ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°: {len(df):,}ä»¶\n")
    f.write(f"- åº—èˆ—æ•°: {len(shop_grouped):,}åº—èˆ—\n")
    f.write(f"- ã‚«ãƒ†ã‚´ãƒªæ•°: {len(mlb.classes_)}ç¨®é¡\n")
    f.write(f"- TF-IDFèªå½™æ•°: {len(tfidf.get_feature_names_out())}èª\n\n")

    f.write("## ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©\n")
    f.write(f"- P1: ã‚«ãƒ†ã‚´ãƒª + æ˜Ÿã®æ•° (ç‰¹å¾´é‡æ¬¡å…ƒ: {features_p1.shape[1]})\n")
    f.write(f"- P2: ã‚«ãƒ†ã‚´ãƒª + ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ç‰¹å¾´é‡æ¬¡å…ƒ: {features_p2.shape[1]})\n")
    f.write(f"- P3: ã‚«ãƒ†ã‚´ãƒª + ãƒ¬ãƒ“ãƒ¥ãƒ¼ + æ˜Ÿã®æ•° (ç‰¹å¾´é‡æ¬¡å…ƒ: {features_p3.shape[1]})\n\n")

    f.write("## é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢çµ±è¨ˆ\n")
    f.write(stats_df.to_string(index=False))
    f.write("\n\n")

    f.write("## ç‰¹å¾´é‡è²¢çŒ®åº¦åˆ†æ\n")
    f.write(contrib_df.to_string(index=False))
    f.write("\n\n")

    f.write("## çµè«–\n")
    avg_review_contrib = contrib_df['ãƒ¬ãƒ“ãƒ¥ãƒ¼è²¢çŒ®åº¦ (P2-P1)'].mean()
    avg_rating_contrib = contrib_df['æ˜Ÿè©•ä¾¡è²¢çŒ®åº¦ (P3-P2)'].mean()

    f.write(f"- ãƒ¬ãƒ“ãƒ¥ãƒ¼æƒ…å ±ã®å¹³å‡è²¢çŒ®åº¦: {avg_review_contrib:+.4f}\n")
    f.write(f"- æ˜Ÿè©•ä¾¡ã®å¹³å‡è²¢çŒ®åº¦: {avg_rating_contrib:+.4f}\n")

    if avg_review_contrib > 0:
        f.write("\nâœ… ãƒ¬ãƒ“ãƒ¥ãƒ¼æƒ…å ±ã®è¿½åŠ ã«ã‚ˆã‚Šã€æ¨è–¦ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¢ºèª\n")

    best_pattern = stats_df.groupby('ãƒ‘ã‚¿ãƒ¼ãƒ³')['å¹³å‡é¡ä¼¼åº¦'].mean().idxmax()
    f.write(f"\nğŸ† æœ€é«˜æ€§èƒ½ãƒ‘ã‚¿ãƒ¼ãƒ³: {best_pattern}\n")

    f.write("\n## å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¹³å‡é¡ä¼¼åº¦\n")
    pattern_avg = stats_df.groupby('ãƒ‘ã‚¿ãƒ¼ãƒ³')['å¹³å‡é¡ä¼¼åº¦'].mean()
    for pattern, score in pattern_avg.items():
        f.write(f"- {pattern}: {score:.4f}\n")

print(f"âœ… çµæœã‚µãƒãƒªãƒ¼ä¿å­˜: {summary_path}")

# å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
print("\n" + "="*80)
print("ğŸ‰ å®Ÿé¨“å®Œäº†ï¼")
print("="*80)
print("\nç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:")
print("  1. pattern_comparison.png - ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥é¡ä¼¼åº¦æ¯”è¼ƒ")
print("  2. scenario_comparison.png - ã‚·ãƒŠãƒªã‚ªåˆ¥æ¯”è¼ƒ")
print("  3. experiment_summary.txt - å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼")
print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
print("  - å…¨å›½ãƒ‡ãƒ¼ã‚¿ã¸ã®æ‹¡å¼µ")
print("  - ã‚ˆã‚Šå¤šæ§˜ãªãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªã§ã®è©•ä¾¡")
print("  - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
